# 1. Introducci√≥n

## ¬øQu√© es Proxmox VE?

Proxmox Virtual Environment o Promxox VE, es un entorno de virtualizaci√≥n de servidores de c√≥digo abierto. Es una distribuci√≥n de linux basada en Debian, con una versi√≥n del Kernel de Ubuntu LTS modificada. Permite el despliegue y gesti√≥n de m√°quinas virtuales y contenedores desde una consola web. Gracias a esta consola, los usuarios pueden gestionar m√°quinas virtuales, contenedores y almacenamiento definido por software.
Dentro de Proxmox existen dos tipos de virtualizaci√≥n compatibles, los contenedores basados en LXC (Linux Containers) y la virtualizaci√≥n con KVM (Kernel-based-Virtual Machine) para las m√°quinas virtuales. Todo esto es posible gracias a la implementaci√≥n de hipervisores KVM y LXC para crear y gestionar entornos virtuales. Los usuarios tienen la capacidad de desplegar m√∫ltiples m√°quinas virtuales y contenedores en un solo servidor f√≠sico, optimizando as√≠ el uso de recursos. La interfaz web permite a los usuarios realizar tareas como la creaci√≥n, clonaci√≥n y migraci√≥n de VMs, as√≠ como la configuraci√≥n de redes y almacenamiento.

## Principales caracter√≠sticas y ventajas

### Caracter√≠sticas

Dentro de Proxmox VE existen gran cantidad de caracter√≠sticas, pero principalmente las m√°s comunes son:
- **Virtualizaci√≥n KVM y LXC:** Soporte completo para KVM, permitiendo la ejecuci√≥n de m√°quinas virutales con gran rendimiento y LXC para contenedores ligeros.
- **Gesti√≥n de cl√∫steres:** Permite la creaci√≥n y gesti√≥n de cl√∫steres de m√∫ltiples nodos, mejorando la escalabilidad y redundancia del sistema
- **Alta disponibilidad (HA):** Ofrece capacidades de alta disponibilidad para VM y CT, asegurando que los servicios cr√≠ticos permanezcan operativos incluso en caso de fallos en el hardware.
- **Interfaz de usuario Web:** Proporciona una interfaz de usuario intuitiva y completa basada en web para la administraci√≥n de todos los aspectos del entorno virtualizado.
- **Copia de seguridad y Restauraci√≥n:** Incluye herramientas integradas para realizar copias de seguridad y restaurar VM y CT de manera eficiente
- **Integraci√≥n con ZFS:** Soporte para el sistema de archivos ZFS, proporcionando capacidades avanzadas de gesti√≥n de almacenamiento, instant√°neas y recopilaci√≥n.
- **Redes definidas por software (SDN):** Facilita la configuraci√≥n y gesti√≥n de redes virtuales complejas dentro del entorno de Promxox VE.
- **Soporte para varios sistemas operativos:** Permite la ejecuci√≥n de m√∫ltiples sistemas operativos, incluyendo Windows, Linux y otros.

### Ventajas

Adicionalmente, Proxmox ofrece varias ventajas frente a otras soluciones de virtualizaci√≥n como Hyper-V de Microsoft o ESXi de VMWare:
- **Coste eficiente:** Proxmox, al ser de c√≥digo abierto, elimina la necesidad de adquirir una licencia con un precio elevado, lo que puede reducir significativamente los costos operativos. Esto es especialmente beneficioso para instituciones y empresas que buscan maximizar su presupuesto en TI.
- **Flexibilidad y Escalabilidad:** La capacidad de gestionar tanto m√°quinas virtuales como contenedores permite a las organizaciones adaptar sus infraestructuras a diferentes necesidades de cargas de trabajo. Adem√°s, la facilidad para a√±adir nuevos nodos al cl√∫ster permite escalar la infraestructura de manera eficiente seg√∫n se necesite.
- **Mejora de disponibilidad y resiliencia:** Las caracter√≠sticas de alta disponibilidad y la gesti√≥n de cl√∫steres aseguran que los servicios cr√≠ticos permanezcan en l√≠nea incluso en caso de fallos de hardware. Esto es crucial para las empresas que requieren una operaci√≥n contin√∫a y sin interrupciones.
- **Simplificaci√≥n de la gesti√≥n de TI:** La interfaz web de Proxmox facilita la administraci√≥n de toda la infraestructura virtual de un solo punto de control. Esto simplifica las tareas de administraci√≥n para los equipos de TI, permitiendo una gesti√≥n m√°s eficiente y reduciendo la carga operativa.
- **Capacitaci√≥n y educaci√≥n:** Proxmox es una plataforma ideal para la ense√±anza de tecnolog√≠as de virtualizaci√≥n y administraci√≥n de sistemas. Los estudiantes pueden aprender a configurar y gestionar entornos virtuales reales, prepar√°ndolos para el mercado laboral.



# 2. Requisitos e Instalaci√≥n

## Hardware m√≠nimo recomendado

Proxmox requiere un hardware adecuado par aun rendimiento √≥ptimo frente a cargas de trabajo exigentes. 

A continuaci√≥n se detallan los requisitos m√≠nimos recomendados para **funciones b√°sicas:**
- **CPU:** Procesador con arquitectura de 64 bits con soporte para virtualizaci√≥n
- **RAM:** 8 GB m√≠nimo para poder ejecutar m√°quinas virtuales y contenedores
- **Almacenamiento:** 16 GB en SSD o HDD (Preferiblemente SSD)
- **Red:** Tarjeta de red gigabit (1Gbps)

Para entornos de producci√≥n o cargas de trabajo exigentes, se recomienda:
- **CPU:** Procesador multin√∫cleo moderno (Intel Xeon o AMD EPYC recomendados)
- **RAM:** 16 GB o m√°s (32 GB o m√°s para alta disponibilidad y grandes cargas)
- **Almacenamiento:**
    - SSD NVMe para el sistema y almacenamiento r√°pido
    - RAID o ZFS con redundancia para mayor seguridad
- **Red:** Tarjetas de red de 10 Gbps si se requiere alto rendimiento

## Descarga e instalaci√≥n de Proxmox VE

### Descargar Proxmox VE

Para poder obtener la √∫ltima versi√≥n de Proxmox VE:
1. Visitar la p√°gina oficial de Proxomox: https://www.proxmox.com/downloads
2. Descargar la imagen ISO m√°s reciente para Proxmox VE

Una vez tenemos la imagen ISO descargada, debemos crear un medio de instalaci√≥n con un USB, mediante rufus o herramientas similares:

![RUFUS](Imagenes/Rufus.jpg)

### Instalaci√≥n de Proxmox VE

Seguidamente instalamos el USB en el servidor d√≥nde queremos instalar PROXMOX y seleccionamos el USB como m√©todo de arranque desde nuestra BIOS o UEFI. Para acceder al men√∫ de arranque es importante mirar la marca de nuestra placa base ya que dependiendo de un modelo u otro la tecla para acceder al men√∫ de arranque puede variar (F2, F9, Del).

![Instalaci√≥n Proxmox](Imagenes/InstalacionProxmox.jpg)


***Se recomienda realizar una instalaci√≥n mediante GUI ya que es m√°s intuitiva y f√°cil de interpretar. Para realizarlo desde terminal se precisan conocimientos m√°s avanzados***

Los siguientes pasos son:
1. Configurar un disco d√≥nde se instalar√° Proxmox
2. Configurar una red asignado una IP fija o mediante DHCP para el servidor de Proxmox
3. Finalizar la instalaci√≥n siguiendo los pasos que se ven en pantalla

Para comprobar que la instalaci√≥n se ha realizado correctamente, reiniciamos y accedemos v√≠a navegador:
- `https://<IP-del-servidor>:8006`

# 3. Gesti√≥n de M√°quinas Virtuales (VMs) y Contenedores (LXCs)

## Diferencias entre VMs y LXCs

### ¬øQu√© es una M√°quina Virtual (VM)?

Una m√°quina virtual o VM en Proxmox es un sistema operativo, completamente virtualizado, que se ejecuta sobre un hipervisor (QEMU/KVM en el caso de Proxmox). La VM tiene su propio Kernel, sistema operativo y recursos virtuales asignados, como CPU, RAM y almacenamiento. Es independiente del sistema anfitri√≥n y se comporta como una computadora f√≠sica.

### ¬øQu√© es un contenedor LXC?

Un contenedor linux o LXC  es una tecnolog√≠a de virtualizaci√≥n a nivel de sistema operativo. En lugar de emular hardware, los contenedores comparten el kernel del sistema anfitri√≥n (Proxmox). Cada contenedor es un entorno aislado con su propio sistema de archivos, usuarios, procesos y red, pero sin la sobrecarga de una VM completa.

### Principales diferencias entre VMs y LXCs

| **Caracter√≠stica**      | **VM (KVM/QEMU)** üñ•Ô∏è                                                      | **Contenedor LXC** üì¶                                           |
|:----------------------- | ------------------------------------------------------------------------- | --------------------------------------------------------------- |
| **Virtualizaci√≥n**      | Completa (Hardware Emulado)                                               | Basada en contenedores (Comparten kernel)                       |
| **Uso del Kernel**      | Tiene su propio kernel                                                    | Comparte el kernel del host                                     |
| **Rendimiento**         | Mayor consumo de recursos                                                 | M√°s eficiente en rendimiento                                    |
| **Aislamiento**         | Alto (Como una m√°quina virtual)                                           | Medio (Depende del kernel del host)                             |
| **Compatiblidad SO**    | Cualquier SO                                                              | Solo Linux                                                      |
| **Consumo de RAM /CPU** | ALTO                                                                      | BAJO                                                            |
| **Migraci√≥n**           | M√°s compleja y requiere recursos                                          | M√°s r√°pida y sencilla                                           |
| **Gesti√≥n de recursos** | Totalmente independiente                                                  | M√°s flexible pero dependiente del host                          |
| **Casos de Uso**        | Aplicaciones que requieren alto aislamiento, sistemas operativos variados | Entornos ligeros, aplicaciones Linux, servicios en contenedores |
**Se recomienda usar VMs en caso de ejecutar Windows o distribuciones Linux con total independencia. Son ideales para aplicaciones cr√≠ticas, bases de datos y entornos que requieren aislamiento total.**

**Se recomienda usar LXCs en caso de ejecutar servicios o aplicaciones Linux con un menor consumo de recursos y una gesti√≥n m√°s sencilla. Son ideales para servidores web, bases de datos ligeras y entornos de desarrollo.**


## Creaci√≥n de una m√°quina virtual (VM)

A continuaci√≥n veremos el proceso de crear una m√°quina virtual dentro de un nodo de Proxmox paso a paso, completamente detallado con capturas del proceso.

**Paso 1:** 

Accedemos a nuestro entorno de proxmox `https://<ip>:8006`

**Paso 2:** 

Accedemos a nuestro nodo:

![Nodo](Imagenes/VM1.jpg)


**Paso 3:** 

Accedemos a la parte de "Create VM":

![Create VM](Imagenes/VM2.jpg)


**Paso 4:**

Se abrir√° una ventana dentro del entorno para configurar la creaci√≥n de nuestra m√°quina virtual:

![VM1](Imagenes/VM3.jpg)


Seguidamente configuramos el sistema operativo de nuestra VM mediante una imagen ISO:

![VM2](Imagenes/VM4.jpg)


**Proxmox trae por defecto ciertas im√°genes ISO configuradas en el sistema, si queremos cargar o a√±adir una ISO adiiconal debemos hacerlo de la siguiente manera:**

![VM3](Imagenes/VM5.jpg)


En mi caso crear√© una VM con una imagen de Kali Linux:

Le damos a siguiente hasta llegar a esta ventana de configuraci√≥n:

![VM4](Imagenes/VM6.jpg)


En esta secci√≥n, dependiendo de los sockets de nuestra CPU y n√∫cleos podemos configurar un valor u otro. Si a√±adimos m√°s n√∫cleos y sockets a la VM, esta tendr√° mayor velocidad de procesamiento.

Seguidamente debemos configurar la memoria RAM, otro par√°metro que depender√° de las capacidades de nuestro servidor y las que le queramos asignar a la VM:

![VM5](Imagenes/VM7.jpg)


Seguidamente en la configuraci√≥n de red podemos escoger si la m√°quina debe disponer de FW o no, entre otras configuraciones las cuales recomiendo no modificar:

![VM6](Imagenes/VM8.jpg)


Una vez configurados los pasos anteriores, podremos visualizar la configuraci√≥n predefinida para nuestra VM en la siguiente ventana:

![VM7](Imagenes/VM9.jpg)


Si le damos a **Finish** la VM se crear√° y podremos ejecutarla.

Finalmente podremos ver nuestra m√°quina creada dentro de nuestro nodo:

![VM Created](Imagenes/VM10.jpg)


## Creaci√≥n de un contenedor (LXC)

Para crear un contenedor en Proxmox, los pasos son muy similares a los de crear una m√°quina virtual dentro de nuestro nodo.

**Paso 1:**
Accedemos a nuestro nodo de Proxmox

![CT1](Imagenes/VM1.jpg)

**Paso 2:**

Accedemos a la secci√≥n de Create CT:

![CT2](Imagenes/VM2.jpg)


**Paso 3:**

Se nos abrir√° una ventana, similar a la de la creaci√≥n de VM, pero un poco distinta:

![CT3](Imagenes/CT1.jpg)


Aqu√≠ debemos configurar el hostname para nuestro contenedor y una contrase√±a para poder acceder al entorno.
Si se precisa, se puede configurar una clave p√∫blica mediante SSH que debemos cargar mediante *Load SSH Key File*

**Paso 4:**

Configurar plantilla del LXC

![CT4](Imagenes/CT2.jpg)


En este caso, solo podemos escoger como plantilla la que se visualiza en pantalla, debido a que LXC dentro de proxmox solo puede correr mediante esa plantilla.

**Paso 5:**

Seguidamente configuramos el almacenamiento de nuestro LXC, al ser un contenedor que ofrecer√° servicios dedicados, no se precisa asignar tanto almacenamiento como en una M√°quina Virtual.

![CT5](Imagenes/CT3.jpg)


**Paso 6:**

En este paso, debemos configurar los cores que queremos que tenga nuestro LXC, teniendo en cuenta los n√∫cleos de los que dispone nuestro procesador y los que queramos asignar para este contenedor:

![CT6](Imagenes/CT4.jpg)


**Paso 7:**

Ahora configuramos la memoria RAM, tal y como lo hemos hecho en la secci√≥n de creaci√≥n de una VM:

![CT7](Imagenes/CT5.jpg)


**Paso 8:**

Seguidamente configuramos los par√°metros de red, si queremos que nuestro LXC disponga de una IP est√°tica o se asigne una IP mediante el DHCP de nuestro router, debemos configurarlo correctamente.
**Recomiendo que se asigne mediante DHCP**

![CT8](Imagenes/CT6.jpg)


**Paso 9:**

Seguidamente configuramos los servidores DNS a los que se conectar√° el contenedor, principalmente recomiendo usar los DNS de Google, esto ya es a elecci√≥n propia.

![CT9](Imagenes/CT7.jpg)


**Paso 10:**

Finalmente se nos mostrar√° una ventana con todas las configuraciones seleccionadas para la creaci√≥n de nuestro LXC:

![CT10](Imagenes/CT8.jpg)


Si le damos a finalizar, se configurar√° y crear√° nuestro LXC, una vez creado podremos visualizarlo en nuestro nodo.


# 4. Almacenamiento y redes

## Tipos de almacenamiento soportados (LVM,ZFS,CEPH,NFS,etc.)

Proxmox VE ofrece una variedad de opciones de almacenamiento para adaptarse a diferentes necesidades empresariales. A continuaci√≥n, se presentan los tipos m√°s comunes:

### LVM (Logical Volume Manager)

LVM es un sistema de gesti√≥n de vol√∫menes l√≥gicos que permite una administraci√≥n flexible del almacenamiento en servidores f√≠sicos.

 ‚úÖ **VENTAJAS:**
- Permite redimensionar vol√∫menes sin afectar los datos.
- Mejora la gesti√≥n del almacenamiento al crear vol√∫menes l√≥gicos sobre discos f√≠sicos o arreglos RAID.
- Compatible con snapshots cuando se usa una combinaci√≥n con LVM-Thin.

‚ùå **CONSIDERACIONES:**
- No ofrece redundancia de datos por s√≠ mismo (Se recomienda RAID)
- No es ideal para entornos con alta demanda de snapshots

 üéØ**USO RECOMENDADO:** Es ideal para servidores con almacenamiento local en discos duros o SSDs proporcionando flexibilidad en la gesti√≥n de vol√∫menes.

### ZFS (Zettabyte File System)

ZFS es un sistema de archivos avanzado con soporte de vol√∫menes que incluye funcionalidades de RAID, compresi√≥n y snapshots nativos.

‚úÖ **VENTAJAS:**
- Protecci√≥n contra corrupci√≥n de datos gracias a su sistema de checksums.
- Soporte nativo para snapshots y clones.
- Integraci√≥n con RAID-Z, eliminando la necesidad de hardware RAID.
- Excelente rendimiento en lectura y escritura con SSDs y cach√© de memoria RAM.

‚ùå **CONSIDERACIONES:**
- Alto consumo de memoria RAM (se recomienda al menos **8 GB de RAM**, preferiblemente m√°s para grandes vol√∫menes).
- Puede requerir ajustes para optimizar el rendimiento en entornos de alta carga.

üéØ**USO RECOMENDADO:** Ideal para entornos que requieren integridad de datos, snapshots frecuentes y administraci√≥n simplificada sin necesidad de RAID por hardware.


### Ceph (Clustered Storage)

Ceph es un sistema de almacenamiento distribuido que proporciona almacenamiento escalable y tolerante a fallos para grandes infraestructuras.

‚úÖ **VENTAJAS:**
- Alta disponibilidad y redundancia de datos (replicaci√≥n autom√°tica).
- Escalabilidad sin interrupciones al agregar m√°s nodos de almacenamiento.
- Integraci√≥n nativa con Proxmox VE para m√°quinas virtuales y contenedores.
- Soporte para almacenamiento en bloques, objetos y sistemas de archivos distribuidos.

‚ùå **CONSIDERACIONES:**
- Requiere al menos **tres nodos** para garantizar redundancia y alta disponibilidad.
- Mayor complejidad de configuraci√≥n y mantenimiento en comparaci√≥n con soluciones locales.

üéØ**USO RECOMENDADO:** Perfecto para empresas con infraestructuras grandes que buscan almacenamiento distribuido, tolerante a fallos y escalable.


### NFS (Network File Storage)

NFS es un protocolo de almacenamiento en red que permite a m√∫ltiples servidores acceder a un sistema de archivos remoto como si fuera local.

‚úÖ **VENTAJAS:**
- F√°cil integraci√≥n con Proxmox VE.
- Permite compartir almacenamiento entre varios nodos sin replicaci√≥n de datos local.
- Ideal para backups centralizados y almacenamiento compartido de im√°genes ISO o plantillas.

‚ùå **CONSIDERACIONES:**
- Dependencia de la red (rendimiento puede verse afectado por latencia).
- No ofrece redundancia de datos por s√≠ mismo (recomendable combinar con RAID o snapshots en el servidor NFS).

üéØ **USO RECOMENDADO:** Excelente para almacenamiento compartido de m√°quinas virtuales, backups y entornos donde la disponibilidad de almacenamiento en red es clave.


### Conclusiones

Cada tipo de almacenamiento en Proxmox VE tiene ventajas y desventajas seg√∫n las necesidades que se precisen. Para una soluci√≥n √≥ptima:
- **LVM** es ideal para almacenamiento local b√°sico con flexibilidad.
- **ZFS** es perfecto para entornos que requieren integridad de datos y snapshots frecuentes.
- **Ceph** es la mejor opci√≥n para almacenamiento distribuido con alta disponibilidad.
- **NFS** es una excelente soluci√≥n para almacenamiento compartido y backups centralizados.

üéØ **RECOMENDACI√ìN:** La elecci√≥n del almacenamiento debe basarse en factores como el rendimiento, redundancia, escalabilidad y facilidad de administraci√≥n, seg√∫n los objetivos de la empresa.


## Redes Virtuales en Proxmox VE

Proxmox VE ofrece una gesti√≥n avanzada de redes virtuales, permitiendo configurar distintos tipos de redes seg√∫n las necesidades del entorno. La flexibilidad de sus sistema de red permite integrar m√°quinas virtuales (VMs) y contenedores (LXCs) de manera eficiente y segura.


### Linux Bridge (vmbrX)

Un **Linux Bridge** act√∫a como un switch virtual, permitiendo que m√∫ltiples VMs y CTs compartan una conexi√≥n de red.

‚úÖ **VENTAJAS:**
- Funciona como un switch virtual, permitiendo comunicaci√≥n entre VMs y con la red f√≠sica.
- F√°cil configuraci√≥n y compatibilidad con m√∫ltiples interfaces f√≠sicas.
- Permite agregar reglas de firewall y configuraci√≥n avanzada con **iptables**.

‚öô **Ejemplo de configuraci√≥n en `/etc/network/interfaces`:**

```auto vmbr0
iface vmbr0 inet static
    address 192.168.1.100
    netmask 255.255.255.0
    gateway 192.168.1.1
    bridge_ports eth0
    bridge_stp off
    bridge_fd 0
```

üí° **Uso recomendado:** Configuraci√≥n est√°ndar para la mayor√≠a de los entornos empresariales, permitiendo que VMs y CTs accedan a la red como si estuvieran conectadas a un switch f√≠sico.

### VLANs (Virtual LANs)

Las VLANs permiten segmentar el tr√°fico de red dentro del mismo switch f√≠sico o virtual, mejorando la seguridad y organizaci√≥n de la red.

‚úÖ **VENTAJAS:**
- Separaci√≥n l√≥gica del tr√°fico sin necesidad de hardware adicional.
- Mejora la seguridad y reduce la congesti√≥n en redes grandes.
- Compatible con switches f√≠sicos y routers que soporten VLAN tagging (IEEE 802.1Q).

‚öô **Ejemplo de configuraci√≥n en `/etc/network/interfaces`:**

```
auto vmbr0.10
iface vmbr0.10 inet static
    address 192.168.10.1
    netmask 255.255.255.0
    vlan-raw-device vmbr0
```

üéØ **USO RECOMENDADO:** Ideal para empresas que requieren segmentaci√≥n de red para separar tr√°fico de departamentos o servicios (por ejemplo, producci√≥n, pruebas, administraci√≥n).

### Bonding (Agregaci√≥n de enlaces - NIC Teaming)

El bonding permite combinar varias interfaces de red f√≠sicas en una sola para mejorar **rendimiento** y **redundancia**.

‚úÖ **VENTAJAS:**
- Mayor ancho de banda al sumar m√∫ltiples interfaces f√≠sicas.
- Tolerancia a fallos: si una interfaz falla, el tr√°fico contin√∫a por las dem√°s.
- Compatible con switches gestionados que soporten **LACP (Link Aggregation Control Protocol)**.

‚öô **Ejemplo de configuraci√≥n de Bonding en `/etc/network/interfaces`:**

```
auto bond0
iface bond0 inet manual
    bond-slaves eth0 eth1
    bond-mode 802.3ad
    bond-miimon 100
    bond-lacp-rate 1
    bond-xmit-hash-policy layer2+3

auto vmbr0
iface vmbr0 inet static
    address 192.168.1.100
    netmask 255.255.255.0
    gateway 192.168.1.1
    bridge_ports bond0
    bridge_stp off
    bridge_fd 0
```

üéØ **USO RECOMENDADO:** Empresas con necesidades de alta disponibilidad y rendimiento en su red, especialmente en entornos con servidores de almacenamiento y bases de datos.

### SDN (Software Defined Network)
Desde Proxmox VE 7.x, se ha incorporado **SDN**, una soluci√≥n avanzada que permite gestionar redes definidas por software para entornos complejos y multi-tenant.

‚úÖ **VENTAJAS:**
- Reducci√≥n de dependencia de hardware de red.
- Creaci√≥n de redes virtuales din√°micas y flexibles.
- Compatibilidad con Open vSwitch y VXLAN para redes privadas escalables.

üéØ**USO RECOMENDADO:** Ideal para proveedores de servicios, centros de datos y grandes infraestructuras con m√∫ltiples usuarios y entornos aislados.

### Conclusi√≥n

Proxmox VE proporciona varias opciones de configuraci√≥n de rd para adaptarse a distintos entornos: 

-  **Linux Bridge** ‚Üí Configuraci√≥n est√°ndar, similar a un switch virtual.  
-  **VLANs** ‚Üí Segmentaci√≥n l√≥gica de redes para mayor seguridad y organizaci√≥n.  
-  **Bonding** ‚Üí Mayor rendimiento y redundancia mediante m√∫ltiples interfaces f√≠sicas.  
-  **SDN** ‚Üí Red definida por software para infraestructuras avanzadas y multi-tenant.


# 5. Alta disponibilidad y Clustering

## Configuraci√≥n de un Cluster

### ¬øQu√© es un cluster en Proxmox VE?

Un **cluster en Proxmox VE** es un grupo de **nodos** (servidores f√≠sicos) que trabajan juntos para administrar recursos de virtualizaci√≥n de manera centralizada. Esto permite funcionalidades avanzadas como:

-  **Migraci√≥n en vivo** de m√°quinas virtuales sin interrupciones.  
-  **Alta disponibilidad (HA)** para minimizar el tiempo de inactividad.  
-  **Gesti√≥n unificada** de m√∫ltiples servidores desde una sola interfaz web.  
-  **Escalabilidad**, agregando m√°s nodos seg√∫n las necesidades.


### Requisitos previos para crear un cluster

Antes de iniciar la configuraci√≥n de un cluster, es muy importante tener el cuenta los siguientes requisitos:

-  **M√∫ltiples servidores con Proxmox VE instalado** (m√≠nimo 2, recomendado 3 o m√°s para HA).  
-  **Red confiable y de baja latencia** (preferiblemente una red de 10 Gbps para evitar problemas de sincronizaci√≥n).  
-  **Tiempo sincronizado entre los nodos** (usar **NTP** es crucial).  
-  **Almacenamiento compartido (NFS, Ceph, iSCSI, etc.)** si se usar√° Alta Disponibilidad.

### Paso a paso: Creaci√≥n de un cluster en Proxmox VE

#### Paso 1: Configurar la red y nombres de Host

Cada nodo en Proxmox VE debe tener una IP est√°tica y los nombres deben resolverse correctamente. 
Se recomienda configurar el archivo **/etc/hosts** dentro de cada nodo.

Para acceder a la consola de un nodo en Proxmox debemos hacerlo desde aqu√≠:
![Cluster1](Imagenes/Cluster1.jpg)


En mi caso dispongo de un solo nodo, pero si queremos crear un nuevo nodo y queremos que se comuniquan entre s√≠ es importante configurar el archivo /etc/hosts a√±adiendo la direcci√≥n IP de cada Cluster

#### Paso 2: Crear un cluster desde el nodo principal

Debemos acceder al nuestro nodo principal y en la consola ejecutar el siguiente comando: ```
```
pvecm create nombre_cluster
```

Esto crear√° el cluster con el nombre del cluster que nosotros le asignemos y generar√° los archivos de configuraci√≥n en **/etc/pve/**

Para verificar el estado del cluster:
```
pvecm status
```

#### Paso 3: Agregar Nodos al cluster

Desde los otros nodos, debemos ejecutar el siguiente comando para unirlo al cluster:
```
pvecm add <IP-NODO-PRINCIPAL>
```

Seguidamente se nos solicitar√° la contrase√±a del usuario root del nodo principal y se sincronizar√°n los datos.

Para ver los nodos existentes y sus conexiones:

```
pvecm nodes
```

#### Paso 4: Habilitar y configurar el Corosync

Corosync es un serviico que permite mantener la comunicaci√≥n entre los nodos existentes. Su configuraci√≥n se puede ver en:

```
systemctl status corosync
```

Si queremos aumentar la tolerancia a errores o fallos, se recomienda usar una segunda interfaz de red dedicada a Corosync, esto mejorar√° la estabilidad del cluster en caso de alguna interrupci√≥n en la red principal.

Si queremos configurar dos interfaces, accedemos al archivo **corosync.conf** y a√±adimos lo siguiente:

```
nodelist {
  node {
    name: proxmox-node1
    nodeid: 1
    ring0_addr: 192.168.1.101
    ring1_addr: 10.10.10.101
  }
  node {
    name: proxmox-node2
    nodeid: 2
    ring0_addr: 192.168.1.102
    ring1_addr: 10.10.10.102
  }
}
```

**Estas IP son a modo ejemplo, es importante introducir las del nodo que se este configurando en el momento, sino fallar√° la creaci√≥n de las dos interfaces**

#### Paso 5: Migraci√≥n de una VM de un nodo a otro

Para comprobar que realmente el cluster est√° bien creado, vamos a probar a migrar una VM de un nodo a otro:

```
qm migrate <ID_VM> <NOMBRE-NODO-DESTINO> --online
```

Ejemplo:
```
qm migrade 107 polete --online
```


Crear un Cluster en Proxmox VE implica tener una alta disponibilidad, escalabilidad y gesti√≥n centralizada de la infraestructura.
Crear un cluster en Proxmox VE nos permite:
- Migrar en vivo VMs sin interrupci√≥n
- Mejorar la redundancia y reducci√≥n de tiempos de inactividad
- Gesti√≥n simple desde la interfaz web de Proxmox
- Compatibilidad con almacenamiento compartido como **Ceph, NFS o iSCSI.**

## Alta disponibilidad (HA) y migraci√≥n de VMs

### ¬øQu√© es la alta disponiblidad (HA)?

La **Alta Disponibilidad (HA)** en Proxmox VE permite que las m√°quinas virtuales (VMs) y contenedores (CTs) sigan funcionando autom√°ticamente en caso de fallo de un nodo.

En un entorno **tradicional**, si un servidor f√≠sico falla, todas las VMs alojadas en √©l quedan inaccesibles. Con **HA en Proxmox VE**, el sistema detecta el fallo y **reanuda autom√°ticamente las VMs en otro nodo disponible**, minimizando el tiempo de inactividad.

Los principales beneficios de HA en Proxmox VE son:
- **Protecci√≥n contra fallos de hardware**: Si un nodo falla, las VMs se reinician en otro nodo disponible.
- **Gesti√≥n autom√°tica**: No requiere intervenci√≥n manual en caso de fallo.
- **Integraci√≥n nativa** con el sistema de clustering de Proxmox.
- **M√°xima continuidad del negocio** y reducci√≥n de interrupciones.

### Requisitos previos para configurar HA en Proxmox VE

Antes de habilitar HA en Proxmox VE es muy importante cumplir con los siguientes requisitos:

-  **Cluster Proxmox VE configurado** con al menos **tres nodos**.  
-  **Almacenamiento compartido** (Ceph, NFS, iSCSI, etc.) para que todas las VMs sean accesibles desde cualquier nodo.  
-  **Quorum activo** en el cluster para evitar problemas de aislamiento.  
-  **Red estable y de baja latencia** para evitar falsos positivos en la detecci√≥n de fallos.

### Configuraci√≥n de HA en Proxmox VE

#### Paso 1: Verificar el estado del cluster

Antes de activar HA en Proxmox VE, debemos comprobar qu√© el cluster este funcionando correctamente:

```
pvecm status
```

Los nodos activos deben mostrar en estado **"online"** .

#### Paso 2: Agregar los nodos al grupo de HA

Se debe crear un grupo HA para definir qu√© nodos pueden alojar VMs en caso de fallo.

Desde la consola de uno de los nodos, escribimos lo siguiente:

```
ha-manager add-group ha-cluster --nodes proxmox-node1,proxmox-node2,proxmox-node3
```

Para verificar la creaci√≥n del grupo HA:

```
ha-manager status
```

#### Paso 3: Habilitar Alta Disponibilidad para una VM o un LXC

Para a√±adir una m√°quina virtual al grupo o sistema de HA, escribimos lo siguiente:

```
ha-manager add vm:<ID_VM> --group <NOMBRE_GRUPO_HA>
```

Desde la interfaz gr√°fica de Proxmox:

1. Ir a **Datacenter ‚Üí HA**.
2. Hacer clic en **Add** y seleccionar la VM o CT que deseas proteger.
3. Asignarla al **grupo de HA** creado.
4. Seleccionar la pol√≠tica de reinicio autom√°tico.

Ahora debemos verificar que la VM est√© en la lista de HA con:

```
ha-manager status
```


### Migraci√≥n de VMs

La **migraci√≥n de VMs** es una funcionalidad clave en clusters de Proxmox VE. Permite mover una m√°quina virtual de un nodo a otro **sin detenerla** (**Live Migration**) o con una breve interrupci√≥n (**Offline Migration**).

#### Migraci√≥n en Vivo (Live Migration)

Este m√©todo de migraci√≥n se usa para mover VMs sin tiempo de inactividad y solo es posible si la VM est√° en **almacenamiento compartido**

Para migrar una VM en vivo desde la l√≠nea de comandos desde nuestro nodo principal:

```
qm migrate <ID_VM> <NOMBRE_NODO> --online
```

O desde la interfaz gr√°fica:

1. Seleccionar la VM.
2. Hacer clic en **Migrate**.
3. Elegir el nodo de destino.
4. Iniciar la migraci√≥n sin detener la VM.

#### Migraci√≥n Offline (Cold Migration)

Este m√©todo de migraci√≥n se usa cuando la VM est√° en almacenamiento local en un nodo y es importante que la VM este apagada antes de migrarla.

Comando para migrar la VM apagada:

```
qm migrate <ID_VM> <NOMBRE_NODO>
```


#### Diferencias entre HA y Live Migration

| Caracter√≠sticas                    | Alta Disponiblidad (HA)          | Live Migration                      |
| ---------------------------------- | -------------------------------- | ----------------------------------- |
| Objetivo                           | Recuperar VMs tras un fallo      | Mover VMs entre nodos sin apagarlas |
| Tiempo de Inactividad              | Casi nulo (Pero hay un reinicio) | Ninguno                             |
| Requiere cluster                   | SI                               | SI                                  |
| Requiere almacenamiento compartido | SI                               | SI                                  |
| Autom√°tico / Manual                | Autom√°tico                       | Manual                              |
| √ìptimo para                        | Protecci√≥n Ante Fallos           | Mantenimiento sin Cortes            |

Alta Disponibilidad y Migraci√≥n de VMs en Proxmox VE** son funciones clave para infraestructuras empresariales que buscan m√°xima estabilidad y m√≠nimo tiempo de inactividad

- Alta Disponibilidad (HA) garantiza que si un nodo falla, las VMs se reinicien en otro nodo sin intervenci√≥n manual.  
- Live Migration permite mover VMs entre nodos **sin interrupciones**, ideal para mantenimiento de servidores.  
- Ambas funcionalidades juntas** permiten una **infraestructura robusta**, resistente a fallos y con alta flexibilidad.

**RECOMENDACI√ìN:** Implementar HA en clusters con **tres o m√°s nodos**, usar **almacenamiento compartido** y asegurar una **red r√°pida y confiable** para maximizar el rendimiento.



# 6. Seguridad y administraci√≥n

## Usuarios, roles y permisos

Promxox VE cuenta con un sistema **robusto y flexible de gesti√≥n de usuarios y permisos**, permitiendo a los administradores asignar roles espec√≠ficos seg√∫n las necesidades de seguridad y administraci√≥n.

Esto es clave para:
- Restringir accesos innecesarios y proteger la infraestructura
- Delegar responsabilidades de manera controlada
- Garantizar el cumplimiento de buenas pr√°cticas de seguridad

#### Usuarios 

Un **usuario** en Proxmox es una cuenta con credenciales que permiten el acceso a la plataforma. Se pueden autenticar mediante diferentes m√©todos:

- **Linux PAM** (`pam`) ‚Üí Autenticaci√≥n local basada en usuarios del sistema.  
- **Proxmox VE Authentication Server** (`pve`) ‚Üí Usuarios gestionados dentro de Proxmox sin dependencia del sistema.  
- **Active Directory / LDAP** (`ldap`) ‚Üí Integraci√≥n con directorios empresariales para autenticaci√≥n centralizada.  
- **OpenID / SSO** (`openid`) ‚Üí Integraci√≥n con proveedores de identidad como Google, Microsoft o Keycloak.

##### Crear un Usuario en la Interfaz Web

1. Ir a **Datacenter ‚Üí Permissions ‚Üí Users**.
2. Hacer clic en **Add**.
3. Ingresar el **nombre de usuario**, dominio (`pam`, `pve`, `ldap`), y tipo de autenticaci√≥n.
4. Asignar un **rol**.
5. Guardar los cambios.

##### Crear un Usuario desde la L√≠nea de Comandos

```
pveum user add usuario@pve --password MiContrase√±aSegura
```

#### Roles

Un rol define los permisos que tiene un usuario dentro del sistema. Proxmox incluye roles predefinidos, pero tambi√©n se pueden crear roles personalizados.

| Rol               | Descripci√≥n                                                                       |
| ----------------- | --------------------------------------------------------------------------------- |
| Administrador     | Acceso total a todo el sistema                                                    |
| NoAccess          | Bloquea el accesso (√∫til para revocar permisos temporalmente)                     |
| PVEAdmin          | Permite administrar Proxmox, pero sin acceso a configuraci√≥n de usuarios ni redes |
| PVEUser           | Puede iniciar/detener VMS y ver recursos, pero no modificarlos                    |
| PVEDatastoreAdmin | Puede gestionar almacenamiento, backups y snapshots                               |
| PVEDatastoreUser  | Puede ver almacenamiento pero no modificarlo                                      |
| PVEMonitor        | Solo acceso de lectura para monitoreo del sistema                                 |
##### Asignar un rol a un usuario desde la Interfaz Web

1. Ir a datacenter - Permissions - Users
2. Seleccionar el usuario
3. Hacer click en Modify y asingar el rol deseado

##### Asignar un rol a un usuario desde la l√≠nea de comandos

```
pveum acl modify / -user usuario@pve -role PVEUser
```

#### Permisos en Proxmox VE

Los **permisos** en Proxmox definen qu√© acciones puede realizar un usuario sobre un **objeto** espec√≠fico (VMs, contenedores, almacenamiento, etc.).

##### Estructura de permisos en Proxmox VE

Los permisos se asignan en una estructura jer√°rquica de objetos:

üìÇ **Datacenter** ‚Üí Contiene todos los nodos y recursos.  
üìç **Nodo** (`/nodes/nodo1`) ‚Üí Servidores individuales dentro del cluster.  
üì¶ **M√°quina Virtual** (`/qemu/100`) ‚Üí VMs espec√≠ficas.  
üóÑ **Almacenamiento** (`/storage/local`) ‚Üí Espacios de almacenamiento.

###### Asignar un permiso a un usuario en un nodo espec√≠fico

```
pveum acl add /nodes/proxmox-node1 -user usuario@pve -role PVEUser
```

###### Revocar un permiso a un usuario

```
pveum acl delete /nodes/proxmox-node1 -user usuario@pve -role PVEUser
```


## Actualizaci√≥n y mantenimiento del sistema

El mantenimiento y actualizaci√≥n regular de Proxmox VE es fundamental para asegurar un entorno seguro, estable y optimizado. Esto incluye la instalaci√≥n de parches de seguridad, nuevas versiones del sistema y monitoreo continuo para prevenir problemas antes de que ocurran.

### Importancia de mantener Proxmox actualizado

‚úÖ **Seguridad** ‚Üí Se corrigen vulnerabilidades y se refuerza la protecci√≥n contra amenazas.  
‚úÖ **Rendimiento** ‚Üí Se optimizan recursos y se mejoran tiempos de respuesta del sistema.  
‚úÖ **Compatibilidad** ‚Üí Se garantiza la compatibilidad con hardware y nuevas funciones.  
‚úÖ **Correcci√≥n de errores (bug fixes)** ‚Üí Se solucionan fallos detectados en versiones anteriores.


### Configuraci√≥n correcta de los repositorios 

Proxmox VE tiene **tres tipos de repositorios**:

 - **Enterprise Repository (`pve-enterprise`)** ‚Üí Solo disponible para suscriptores de Proxmox.  
 - **No-Subscription Repository (`pve-no-subscription`)** ‚Üí Gratuito, pero sin garant√≠a de estabilidad.  
 - **Test Repository (`pvetest`)** ‚Üí Para pruebas y desarrollo, **no recomendado en producci√≥n**.

#### Configurar un repositorio gratuito pve-no-subscription

Si no se dispone de una suscripci√≥n empresarial, debemos editar el archivo de repositorios:

```
nano /etc/apt/sources.list.d/pve-enterprise.list
```

Y debemos comentar la siguiente l√≠nea del repositorio empresarial:

```
# deb https://enterprise.proxmox.com/debian/pve bookworm pve-enterprise
```

Seguidamente debemos agregar el repositorio gratuito:

```
echo "deb http://download.proxmox.com/debian/pve bookworm pve-no-subscription" > /etc/apt/sources.list.d/pve-no-subscription.list
```

Finalmente debemos actualizar la lista de paquetes para que se apliquen las configuraciones previas:

```
sudo apt update
```

### Actualizaci√≥n de Proxmox VE

#### Paso 1: Verificar la versi√≥n actual de proxmox

```
pveversion -v
```

#### Paso 2: Actualizar paquetes del sistema

```
apt update && apt dist-upgrade -y
```

#### Paso 3: Verificar que todo funciona correctamente

Despu√©s de reiniciar el sistema, revisamos el estado del cluster y servicios:

```
pvecm status  # Verifica el cluster
systemctl status pve-cluster pvedaemon pveproxy  # Verifica servicios clave
```

### Mantenimiento preventivo de Promxox VE

Realizar un mantenimiento regular sobre nuestro Proxmox VE ayuda a evitar problemas.

A continuaci√≥n se listan varias recomendaciones de mantenimiento para evitar problemas a futuro en nuestro entorno:

#### Monitorear el estado del sistema

Se recomienda revisar con frecuencia el uso de CPU, RAM y almacenamiento de nuestro Proxmox VE.

Para evaluar el rendimiento del sistema desde CLI:

```
pveperf
```

#### Gestionar espacio en disco

Revisar el uso de almacenamiento con:

```
df -h
```

#### Verificar la salud de los discos

```
smartctl -a /dev/sdX
```

#### Rotaci√≥n de logs para evitar saturaci√≥n en disco

Revisar y limpiar logs grandes en **/var/log/:**

```
journalctl --vacum-size=500M
```

#### Conclusi√≥n

El mantenimiento y la actualizaci√≥n de Promxox VE es cr√≠tico para garantizar la estabilidad y seguridad del sistema. Se recomienda:
- **Actualizar regularmente** para corregir vulnerabilidades y mejorar el rendimiento.  
-  **Configurar correctamente los repositorios** para evitar problemas de compatibilidad.  
-  **Realizar mantenimiento preventivo** para evitar saturaci√≥n de recursos.  
-  **Implementar buenas pr√°cticas de seguridad** para proteger la infraestructura.
